OKBQA_Task2
=============
Dialog Corpus and Evaluation
-----------------

# Introduction
Along with interest in AI research, researches and application development for AI Agents such as Amazon Echo, Apple Siri, and Google Assistant are also being sparked. These conversational agents focus on task-oriented conversations, that is, conversations that respond to user's requests (e.g. "play music").

However, actual human-to-human conversations are not made by one-sided requests and responses. Instead, they get information from each other and are asked to re-request shortcomings of the other's request. For examples, when a student is taking a class with a teacher, it is a good idea to ask what you do not know. In addition, person-to-person conversations carry on a consistent conversation on a single topic. When you talk about a topic, you communicate with each other based on the knowledge you know, and if you do not know each other, you are asked to ask your opponent to get information.



## Task 2. Dialog Corpus and Evaluation aims to develop a conversational agent that can achieve the following goals:

Conduct consistent conversations based on given knowledge

Generate conversation that provides knowledge to its opponent based on given knowledge

Generate conversation that find insufficient knowledge and acquire knowledge of the other.

Goals
In order to build and evaluate conversation agents that achieve the above goals, it is necessary to have good learning data, sufficient evaluation methods, and implementation of a dialogue model based on them.

In OKBQA Hackathon in 2018, Task 2. The Dialog Corpus and Evaluation aims to build and evaluate a conversation agent with the goal of sharing the following accomplishments, encouraging participants to participate in this task.

Sharing and discussing the training data (dialog corpus)

Sharing and discussing how to build training data

Evaluation metric

Dialog model (baseline model)

Conditions
There are no special restrictions on participating in this task.
